\documentclass{beamer}
\usepackage{graphicx}
\usepackage{ctex}
\usepackage{ctex, hyperref}
\usepackage[T1]{fontenc}
\usepackage{amssymb}

% other packages
\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra}
\usepackage{graphicx,pstricks,listings,stackengine}
\usepackage{caption, subfigure}

% xmu beamer
\usepackage[blue]{TongjiBeamer}
\author{xxy}
\title{inverse game}
\institute{tju}
\date{\today}

\begin{document}
	\begin{frame}
		\titlepage
		\begin{figure}[htpb]
       		\begin{center}
            \includegraphics[width=0.2\linewidth]{pic/tongji_logo.png}
        		\end{center}
    		\end{figure}
	\end{frame}
	
	\begin{frame}{Network Games of Linear-Quadratic}
	\tiny
	payoff:
	\begin{center}
	 	$U_i=a_ib_i-\frac{1}{2}a_i^2+\beta a_i \sum\limits_{j\in v} G_{ij} a_j$
	 \end{center}
	 	Taking the first-order derivative of the payoff $u_i$:
	 	\begin{center}
	 		$\frac{\partial U_i}{\partial a_i}=b_i-a_i+\beta (G \boldsymbol{a})_i$
	 	\end{center}
	 	pure strategy Nash equilibrium action $\boldsymbol{a}$:
	 	\begin{center}
	 		$(I-\beta G)a=b$
	 	\end{center}
	 	It is often easier to observe the
individual actions a,
\begin{align*}
&\underset{\mathbf{G},\mathbf{B}}{\min}f(\mathbf{G},\mathbf{B})\\
&=\|(\mathbf{I}-\beta\mathbf{G})\mathbf{A}-\mathbf{B}\|_{F}^{2}+\theta_{1}\|\mathbf{G}\|_{F}^{2}+\theta_{2}\|\mathbf{B}\|_{F}^{2},\\
&\text{s.t. }G_{ij}=G_{ji},~G_{ij}\geq0,~G_{ii}=0~\text{for}~\forall i,j\in\mathcal{V},\\
&\quad\|\mathbf{G}\|_{1}=N,
\end{align*}
	\end{frame}
	\begin{frame}{Compressed sensing}
		considers the model problem of recovering an
input vector:
\begin{center}
	$y=Af+e,\quad f\in \mathbb{R}^n,\quad A\in M_{m\times n}$
\end{center}
if has full rank,
then one can clearly recover the plaintext from  $Af$
	\end{frame}
	
	
	\begin{frame}{Problem formulation}
	\tiny
	Consider the parameter identification of the following stochastic system:
\[
y_{k + 1} = \theta^{T}\varphi_{k} + w_{k + 1}, \quad k \geq 0 \tag{1}
\]
\begin{itemize}
 \item $\theta$ is the unknown $r$-dimensional parameter vector
 \item $\varphi_{k} \in \mathbb{R}^{r}$ is the regressor vector
 \item $y_{k + 1}$ $w_{k + 1}$ is the system output 
 \item $w_{k+1}$  is noise
 \end{itemize}

Denote the family of $\sigma$-algebras $\{\mathcal{F}_{k}\}$ as:
%

%\mathcal{F}_{k} &\triangleq \sigma\{y_{k}, \cdots, y_{0}, u_{k - 1}, \cdots, u_{0}, w_{k}, \cdots, w_{0}, \\
%& \quad w_{k}^{\prime}, \cdots, w_{0}^{\prime}\}, \quad k \geq 1 \tag{2}
%
%\]
%where $\{w_{k}^{\prime}\}$ is a possible sequence of exogenous input signals to the system (see Fig. 1). Moreover, denote the parameter vector $\theta$ and the index set of its zero elements as:
%
%By assuming that the regressor $\varphi_{k}$ is $\mathcal{F}_{k}$-measurable for each $k \geq 1$, the problem is to infer the set $A^{*}$ and to estimate the unknown but nonzero elements in $\theta$ based on the system observations $\{\varphi_{k}, y_{k + 1}\}_{k = 1}^{N}$.
	\end{frame}
	\begin{frame}
%	\tiny
	 A time - independent digraph $\mathcal{G}=(\mathcal{V},\mathcal{E})$ is called strongly connected if for any $i,j\in\mathcal{V}$, there exists a directed path from $i$ to $j$.
	 
	 \vspace{0.2cm}
	 
	  A nonnegative stochastic matrix $A$ is called doubly stochastic if $A\mathbf{1}=\mathbf{1}$ and $\mathbf{1}^TA = \mathbf{1}^T$.

In the paper we consider a network with $N$ agents. The inter - action relationship among agents is described by a time - varying digraph $\mathcal{G}(k)=(\mathcal{V},\mathcal{E}(k))$, where $k$ is the time, $\mathcal{V}=\{1,\ldots,N\}$ is the agent set, and $\mathcal{E}(k)\subseteq\mathcal{V}\times\mathcal{V}$ is the edge set. By $(i,j)\in\mathcal{E}(k)$ we mean that agent $j$ can receive information from agent $i$ at time $k$. Assume $(i,i)\in\mathcal{E}(k)$ for all $k = 1,2,\ldots$. Denote the neighbors of agent $i$ at time $k$ by $N_i(k)=\{j\in\mathcal{V}:(j,i)\in\mathcal{E}(k)\}$. The adjacency matrix associated with the graph is denoted by $W(k)=[w_{ij}(k)]_{i,j = 1}^N$, where $w_{ij}(k)>0$ if and only if $(j,i)\in\mathcal{E}(k)$, otherwise $w_{ij}(k)=0$.

The dynamics of agent $i$, $i = 1,\ldots,N$ is given by
\[y_{i,k + 1}=\boldsymbol{\phi}_{i,k}^T\boldsymbol{\theta}^* + d_{i,k + 1}\tag{1}\]
where $\boldsymbol{\theta}^*\in\mathbb{R}^{l\times1}$ is unknown for all agents, $\boldsymbol{\phi}_{i,k}\in\mathbb{R}^{l\times1}$, $y_{i,k + 1}\in\mathbb{R}$, and $d_{i,k + 1}\in\mathbb{R}$ are the input vector, output, and noise of agent $i$, respectively. The measured output of agent $i$ is given by a binary sensor
\[z_{i,k + 1}=\mathbb{I}_{[y_{i,k + 1}<c_{i,k}]}\tag{2}\]
where $\{c_{i,k}\}_{k\geq1}$ is a sequence of time - varying thresholds, which can online be tuned and will be specified later on. For each agent $i\in\mathcal{V}$, the problem of distributed identification is to estimate $\boldsymbol{\theta}^*$ by using its local input sequence $\{\boldsymbol{\phi}_{i,k}\}$, the binary - valued measurements $\{z_{i,k + 1}\}$, and the information obtained from exchange with its adjacent neighbors.
	\end{frame}
	\end{document}